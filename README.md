---

<div align="center">    

# Making the Best of Both Worlds: A Domain-Oriented Transformer for Unsupervised Domain Adaptation

Wenxuan Ma, Jinming Zhang, [Shuang Li](https://shuangli.xyz), , [Chi Harold Liu](https://scholar.google.com/citations?user=3IgFTEkAAAAJ&hl=en), [Yulin Wang](https://www.rainforest-wang.cool/), and Wei Li

[![Paper](https://img.shields.io/badge/paper-arxiv.2208.01195-B31B1B.svg)](https://arxiv.org/abs/2208.01195)

</div>

Official implementation of our ACM MM 2022 paper "Making the Best of Both Worlds: A Domain-Oriented Transformer for Unsupervised Domain Adaptation" (DOT). 

Code is coming soon.

## Framework Overview

In this work, we propose a new UDA paradigm that simultaneously learns multiple feature embedding spaces with different specification. The comparison between our new paradigm and the classical ones is shown in the figure.

<img src="resources/paradigm_comparison.png" width=100% height=100%>

## Contact

If you have any questions about our code, feel free to contact us or describe your problem in [Issues](https://github.com/BIT-DA/SePiCo/issues/new).

Email address: wenxuanma@bit.edu.cn; jinming-zhang@bit.edu.cn.

<div align="right">
<b><a href="#overview">â†¥</a></b>
</div>